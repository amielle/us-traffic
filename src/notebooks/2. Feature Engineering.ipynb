{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering\n",
    "\n",
    "The following notebook provides functions for retrieving the following features for modeling. This notebook mostly serves as a dump for functions explored but processed dataframes per station and state can be retrieved by running *src/preprocess_trafficdata.py*. \n",
    "\n",
    "Some of the features that were explored are the following:\n",
    "\n",
    "* Historical traffic volume\n",
    "    * determined by *traffic_volume_counted_after*\n",
    "* Temporal features\n",
    "    * Cyclical timestamps (expressed as sin & cos values)\n",
    "        * Month of year\n",
    "        * Day of month\n",
    "        * Day of week\n",
    "        * Hour of day\n",
    "    * Part of day (0-5AM, 6-11AM, 12-5PM, 6-11PM)\n",
    "    * Weekend vs. weekday\n",
    "* Spatial features\n",
    "    * longitude\n",
    "    * latitude\n",
    "    * fips state code\n",
    "    * station_id\n",
    "    * urban/rural from functional_classification_name\n",
    "    * Additionally, neighboring stations may also be retrieved by sorting and retrieving the [distances between the longitude and latitude values](https://mypages.iit.edu/~maslanka/3Dcoordinates.pdf) of stations\n",
    "* Traffic features - Can be disregarded if volume trends to be checked are for locations relative to the station (no need for lane/direction in this case)\n",
    "    * lane of travel\n",
    "    * direction of travel \n",
    "\n",
    "Table of contents:\n",
    "- [2.1 Prerequisites](#1)\n",
    "- [2.2 Load raw data](#2)\n",
    "- [2.3 Modify missing and incorrect data points](#3)\n",
    "- [2.4 Functions for extracting features](#4)\n",
    "- [2.5 Guide for using pre-processed data as input (LSTM)](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "\n",
    "## 2.1 Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries. Before running the notebook, it is assumed that the user has already installed the required libraries contained in *requirements.txt* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from math import sin, cos, pi\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modify to adjust figure sizes\n",
    "pylab.rcParams['figure.figsize'] = (12, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the notebooks and utility functions are under src folder of the repository, `os.chdir(\"..\")` is used as an easy way to move back one directory to access the folders. This serves as a workaround for the initial exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.preprocess' from 'C:\\\\Users\\\\combi\\\\Documents\\\\gitrepos\\\\us-traffic\\\\src\\\\utils\\\\preprocess.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from utils.config import filenames \n",
    "from utils import datautils, preprocess\n",
    "\n",
    "# Easy way to reload utility functions with changes\n",
    "importlib.reload(datautils)\n",
    "importlib.reload(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "\n",
    "## 2.2 Load raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the DATA_LOCATION directory as needed. This configuration sets it as src/data in the repository. This assumes that the required data is already located within the directory e.g.\n",
    "```\n",
    "us-traffic\n",
    "│   ...    \n",
    "│\n",
    "└───src\n",
    "|   |   datasetdownloader.py\n",
    "│   │   ...\n",
    "│   │\n",
    "│   └───data  <- (DATA_LOCATION)\n",
    "|       |    dot_traffic_2015.txt.gz\n",
    "|       |    dot_traffic_stations_2015.txt.gz\n",
    "│       |\n",
    "|       └─── ...\n",
    "|\n",
    "...\n",
    "```\n",
    "\n",
    "Alternatively, the user can also download the files via the datadownloader.py script under src."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LOCATION = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main files under the dataset:\n",
    "- Traffic data - dot_traffic_2015.txt.gz\n",
    "- Traffic stations data - dot_traffic_stations_2015.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert FIPS data. Assumes that the location of the FIPS files (fips_code.csv and fips_latlong.csv) are located under *src/data* within the us-traffic repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIPS_LOCATION = DATA_LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FIPS state codes reference from 'fips_code.csv' ...\n",
      "Loading approximate FIPS coordinates reference from 'fips_latlong.csv' ...\n",
      "Finished loading data.\n"
     ]
    }
   ],
   "source": [
    "fips_df, fips_loc_df = datautils.load_other_datasets(FIPS_LOCATION,\n",
    "                                                    filenames[\"FIPS_CODE\"],\n",
    "                                                    filenames[\"FIPS_LOC\"])\n",
    "fips_state_ref = datautils.create_fips_ref(fips_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 2.3 Modify missing and incorrect data points\n",
    "\n",
    "Based on EDA done in the previous notebook, it was seen that there were some data points with missing values (0 or null) and some values with an incorrect offset with regards to the tens place (e.g. ~900 longitude values instead of ~90).\n",
    "\n",
    "If new data such as traffic data from 2016 onwards will be used, EDA must be done to check anomalies in the data for cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded preprocesssed traffic data.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    traffic_data = preprocess.read_df_feather(file_dir=DATA_LOCATION,\n",
    "                                          filename=\"merged_traffic_data\")\n",
    "    print(\"Loaded preprocesssed traffic data.\")\n",
    "except:\n",
    "    # Loading raw data\n",
    "    traffic_data, traffic_stations = datautils.load_traffic_datasets(\n",
    "                                                    DATA_LOCATION,\n",
    "                                                    filenames[\"TRAFFIC_DATA\"],\n",
    "                                                    filenames[\"TRAFFIC_STATIONS\"])\n",
    "\n",
    "    print(\"Processing traffic data.\")\n",
    "\n",
    "    traffic_vol_cols = [col for col in traffic_data.columns \n",
    "                    if 'traffic_volume' in col]\n",
    "\n",
    "    traffic_data = preprocess.process_raw_data(traffic_data,\n",
    "                                               traffic_stations,\n",
    "                                               traffic_vol_cols,\n",
    "                                               fips_loc_df)\n",
    "    \n",
    "    # Save processed traffic data for later use\n",
    "    preprocess.save_df_feather(df=traffic_data,\n",
    "                            file_dir=DATA_LOCATION,\n",
    "                            filename=\"merged_traffic_data\",\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'california'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips_state_ref[fips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = traffic_data[traffic_data[\"fips_state_code\"] == \n",
    "                      fips].sort_values(by=\"date\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191185, 34)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>traffic_volume_counted_after_0000_to_0100</th>\n",
       "      <th>traffic_volume_counted_after_0100_to_0200</th>\n",
       "      <th>traffic_volume_counted_after_0200_to_0300</th>\n",
       "      <th>traffic_volume_counted_after_0300_to_0400</th>\n",
       "      <th>traffic_volume_counted_after_0400_to_0500</th>\n",
       "      <th>traffic_volume_counted_after_0500_to_0600</th>\n",
       "      <th>traffic_volume_counted_after_0600_to_0700</th>\n",
       "      <th>traffic_volume_counted_after_0700_to_0800</th>\n",
       "      <th>traffic_volume_counted_after_0800_to_0900</th>\n",
       "      <th>...</th>\n",
       "      <th>traffic_volume_counted_after_2300_to_2400</th>\n",
       "      <th>station_id</th>\n",
       "      <th>fips_state_code</th>\n",
       "      <th>functional_classification_name</th>\n",
       "      <th>direction_of_travel_name</th>\n",
       "      <th>longitude</th>\n",
       "      <th>fips_county_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>daily_tot_vol</th>\n",
       "      <th>daily_avg_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>3838</td>\n",
       "      <td>4378</td>\n",
       "      <td>3177</td>\n",
       "      <td>1979</td>\n",
       "      <td>1547</td>\n",
       "      <td>2052</td>\n",
       "      <td>829</td>\n",
       "      <td>2378</td>\n",
       "      <td>2843</td>\n",
       "      <td>...</td>\n",
       "      <td>2806</td>\n",
       "      <td>074870</td>\n",
       "      <td>6</td>\n",
       "      <td>Urban: Principal Arterial - Other Freeways or ...</td>\n",
       "      <td>North</td>\n",
       "      <td>118.458582</td>\n",
       "      <td>37</td>\n",
       "      <td>34.158876</td>\n",
       "      <td>88307</td>\n",
       "      <td>3679.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>72</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>035730</td>\n",
       "      <td>6</td>\n",
       "      <td>Rural: Minor Arterial</td>\n",
       "      <td>South</td>\n",
       "      <td>122.014027</td>\n",
       "      <td>21</td>\n",
       "      <td>39.521813</td>\n",
       "      <td>3100</td>\n",
       "      <td>129.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>035710</td>\n",
       "      <td>6</td>\n",
       "      <td>Rural: Principal Arterial - Other</td>\n",
       "      <td>North</td>\n",
       "      <td>121.688095</td>\n",
       "      <td>7</td>\n",
       "      <td>39.415027</td>\n",
       "      <td>3344</td>\n",
       "      <td>139.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>462</td>\n",
       "      <td>365</td>\n",
       "      <td>258</td>\n",
       "      <td>176</td>\n",
       "      <td>159</td>\n",
       "      <td>228</td>\n",
       "      <td>369</td>\n",
       "      <td>542</td>\n",
       "      <td>723</td>\n",
       "      <td>...</td>\n",
       "      <td>345</td>\n",
       "      <td>023040</td>\n",
       "      <td>6</td>\n",
       "      <td>Urban: Principal Arterial - Interstate</td>\n",
       "      <td>North</td>\n",
       "      <td>122.360431</td>\n",
       "      <td>89</td>\n",
       "      <td>40.570947</td>\n",
       "      <td>21680</td>\n",
       "      <td>903.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>032080</td>\n",
       "      <td>6</td>\n",
       "      <td>Urban: Principal Arterial - Other</td>\n",
       "      <td>South</td>\n",
       "      <td>121.065652</td>\n",
       "      <td>61</td>\n",
       "      <td>38.904086</td>\n",
       "      <td>3095</td>\n",
       "      <td>128.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191180</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>155</td>\n",
       "      <td>103</td>\n",
       "      <td>94</td>\n",
       "      <td>82</td>\n",
       "      <td>193</td>\n",
       "      <td>551</td>\n",
       "      <td>651</td>\n",
       "      <td>652</td>\n",
       "      <td>598</td>\n",
       "      <td>...</td>\n",
       "      <td>279</td>\n",
       "      <td>062320</td>\n",
       "      <td>6</td>\n",
       "      <td>Urban: Principal Arterial - Other</td>\n",
       "      <td>West</td>\n",
       "      <td>119.693011</td>\n",
       "      <td>31</td>\n",
       "      <td>36.314007</td>\n",
       "      <td>17001</td>\n",
       "      <td>708.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191181</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>099060</td>\n",
       "      <td>6</td>\n",
       "      <td>Rural: Principal Arterial - Other</td>\n",
       "      <td>South</td>\n",
       "      <td>118.477548</td>\n",
       "      <td>27</td>\n",
       "      <td>37.380907</td>\n",
       "      <td>2281</td>\n",
       "      <td>95.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191182</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>623</td>\n",
       "      <td>389</td>\n",
       "      <td>251</td>\n",
       "      <td>186</td>\n",
       "      <td>328</td>\n",
       "      <td>706</td>\n",
       "      <td>1570</td>\n",
       "      <td>2608</td>\n",
       "      <td>3249</td>\n",
       "      <td>...</td>\n",
       "      <td>1300</td>\n",
       "      <td>055490</td>\n",
       "      <td>6</td>\n",
       "      <td>Urban: Principal Arterial - Other Freeways or ...</td>\n",
       "      <td>North</td>\n",
       "      <td>119.727979</td>\n",
       "      <td>83</td>\n",
       "      <td>34.426955</td>\n",
       "      <td>63699</td>\n",
       "      <td>2654.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191183</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>696</td>\n",
       "      <td>566</td>\n",
       "      <td>431</td>\n",
       "      <td>414</td>\n",
       "      <td>660</td>\n",
       "      <td>1099</td>\n",
       "      <td>1535</td>\n",
       "      <td>1935</td>\n",
       "      <td>2129</td>\n",
       "      <td>...</td>\n",
       "      <td>1133</td>\n",
       "      <td>030150</td>\n",
       "      <td>6</td>\n",
       "      <td>Urban: Principal Arterial - Interstate</td>\n",
       "      <td>South</td>\n",
       "      <td>121.516545</td>\n",
       "      <td>67</td>\n",
       "      <td>38.495536</td>\n",
       "      <td>58870</td>\n",
       "      <td>2452.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191184</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>011040</td>\n",
       "      <td>6</td>\n",
       "      <td>Rural: Principal Arterial - Other</td>\n",
       "      <td>South</td>\n",
       "      <td>124.107946</td>\n",
       "      <td>23</td>\n",
       "      <td>41.013556</td>\n",
       "      <td>4971</td>\n",
       "      <td>207.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180806 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  traffic_volume_counted_after_0000_to_0100  \\\n",
       "0      2015-01-01                                       3838   \n",
       "1      2015-01-01                                         43   \n",
       "2      2015-01-01                                         64   \n",
       "3      2015-01-01                                        462   \n",
       "4      2015-01-01                                         60   \n",
       "...           ...                                        ...   \n",
       "191180 2015-12-31                                        155   \n",
       "191181 2015-12-31                                         25   \n",
       "191182 2015-12-31                                        623   \n",
       "191183 2015-12-31                                        696   \n",
       "191184 2015-12-31                                         31   \n",
       "\n",
       "        traffic_volume_counted_after_0100_to_0200  \\\n",
       "0                                            4378   \n",
       "1                                              54   \n",
       "2                                              54   \n",
       "3                                             365   \n",
       "4                                              32   \n",
       "...                                           ...   \n",
       "191180                                        103   \n",
       "191181                                         20   \n",
       "191182                                        389   \n",
       "191183                                        566   \n",
       "191184                                         32   \n",
       "\n",
       "        traffic_volume_counted_after_0200_to_0300  \\\n",
       "0                                            3177   \n",
       "1                                              57   \n",
       "2                                              31   \n",
       "3                                             258   \n",
       "4                                              21   \n",
       "...                                           ...   \n",
       "191180                                         94   \n",
       "191181                                          4   \n",
       "191182                                        251   \n",
       "191183                                        431   \n",
       "191184                                         28   \n",
       "\n",
       "        traffic_volume_counted_after_0300_to_0400  \\\n",
       "0                                            1979   \n",
       "1                                              31   \n",
       "2                                              24   \n",
       "3                                             176   \n",
       "4                                               9   \n",
       "...                                           ...   \n",
       "191180                                         82   \n",
       "191181                                          2   \n",
       "191182                                        186   \n",
       "191183                                        414   \n",
       "191184                                         14   \n",
       "\n",
       "        traffic_volume_counted_after_0400_to_0500  \\\n",
       "0                                            1547   \n",
       "1                                              27   \n",
       "2                                              23   \n",
       "3                                             159   \n",
       "4                                              13   \n",
       "...                                           ...   \n",
       "191180                                        193   \n",
       "191181                                          3   \n",
       "191182                                        328   \n",
       "191183                                        660   \n",
       "191184                                         19   \n",
       "\n",
       "        traffic_volume_counted_after_0500_to_0600  \\\n",
       "0                                            2052   \n",
       "1                                              38   \n",
       "2                                              46   \n",
       "3                                             228   \n",
       "4                                              14   \n",
       "...                                           ...   \n",
       "191180                                        551   \n",
       "191181                                          4   \n",
       "191182                                        706   \n",
       "191183                                       1099   \n",
       "191184                                         25   \n",
       "\n",
       "        traffic_volume_counted_after_0600_to_0700  \\\n",
       "0                                             829   \n",
       "1                                              39   \n",
       "2                                              48   \n",
       "3                                             369   \n",
       "4                                              26   \n",
       "...                                           ...   \n",
       "191180                                        651   \n",
       "191181                                         13   \n",
       "191182                                       1570   \n",
       "191183                                       1535   \n",
       "191184                                         56   \n",
       "\n",
       "        traffic_volume_counted_after_0700_to_0800  \\\n",
       "0                                            2378   \n",
       "1                                              72   \n",
       "2                                              64   \n",
       "3                                             542   \n",
       "4                                              35   \n",
       "...                                           ...   \n",
       "191180                                        652   \n",
       "191181                                         29   \n",
       "191182                                       2608   \n",
       "191183                                       1935   \n",
       "191184                                        158   \n",
       "\n",
       "        traffic_volume_counted_after_0800_to_0900  ...  \\\n",
       "0                                            2843  ...   \n",
       "1                                             100  ...   \n",
       "2                                             109  ...   \n",
       "3                                             723  ...   \n",
       "4                                              91  ...   \n",
       "...                                           ...  ...   \n",
       "191180                                        598  ...   \n",
       "191181                                        147  ...   \n",
       "191182                                       3249  ...   \n",
       "191183                                       2129  ...   \n",
       "191184                                        159  ...   \n",
       "\n",
       "        traffic_volume_counted_after_2300_to_2400  station_id  \\\n",
       "0                                            2806      074870   \n",
       "1                                              37      035730   \n",
       "2                                              58      035710   \n",
       "3                                             345      023040   \n",
       "4                                              34      032080   \n",
       "...                                           ...         ...   \n",
       "191180                                        279      062320   \n",
       "191181                                         17      099060   \n",
       "191182                                       1300      055490   \n",
       "191183                                       1133      030150   \n",
       "191184                                         81      011040   \n",
       "\n",
       "        fips_state_code                     functional_classification_name  \\\n",
       "0                     6  Urban: Principal Arterial - Other Freeways or ...   \n",
       "1                     6                              Rural: Minor Arterial   \n",
       "2                     6                  Rural: Principal Arterial - Other   \n",
       "3                     6             Urban: Principal Arterial - Interstate   \n",
       "4                     6                  Urban: Principal Arterial - Other   \n",
       "...                 ...                                                ...   \n",
       "191180                6                  Urban: Principal Arterial - Other   \n",
       "191181                6                  Rural: Principal Arterial - Other   \n",
       "191182                6  Urban: Principal Arterial - Other Freeways or ...   \n",
       "191183                6             Urban: Principal Arterial - Interstate   \n",
       "191184                6                  Rural: Principal Arterial - Other   \n",
       "\n",
       "        direction_of_travel_name   longitude  fips_county_code   latitude  \\\n",
       "0                          North  118.458582                37  34.158876   \n",
       "1                          South  122.014027                21  39.521813   \n",
       "2                          North  121.688095                 7  39.415027   \n",
       "3                          North  122.360431                89  40.570947   \n",
       "4                          South  121.065652                61  38.904086   \n",
       "...                          ...         ...               ...        ...   \n",
       "191180                      West  119.693011                31  36.314007   \n",
       "191181                     South  118.477548                27  37.380907   \n",
       "191182                     North  119.727979                83  34.426955   \n",
       "191183                     South  121.516545                67  38.495536   \n",
       "191184                     South  124.107946                23  41.013556   \n",
       "\n",
       "        daily_tot_vol  daily_avg_vol  \n",
       "0               88307    3679.458333  \n",
       "1                3100     129.166667  \n",
       "2                3344     139.333333  \n",
       "3               21680     903.333333  \n",
       "4                3095     128.958333  \n",
       "...               ...            ...  \n",
       "191180          17001     708.375000  \n",
       "191181           2281      95.041667  \n",
       "191182          63699    2654.125000  \n",
       "191183          58870    2452.916667  \n",
       "191184           4971     207.125000  \n",
       "\n",
       "[180806 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.groupby([\"date\", \"station_id\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Functions for extracting features\n",
    "\n",
    "Other functions are located in *utils/preprocess.py*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_df(fips_state_code, save_dir,\n",
    "                    traffic_data=None, traffic_stations=None, overwrite=False):\n",
    "    file_path = f\"{os.path.join(save_dir, str(fips_state_code))}.pkl\"\n",
    "\n",
    "    if overwrite == False and os.path.isfile(file_path):\n",
    "        print(f\"File already exists. Retrieving DataFrame from '{file_path}'.\")\n",
    "        df = read_df_feather(save_dir, filename=fips_state_code)\n",
    "        return df\n",
    "\n",
    "    sub_df_cols = temporal_cols + new_traffic_vol_cols + common_cols\n",
    "    sub_df = traffic_data[traffic_data[\"fips_state_code\"]\n",
    "                          == fips_state_code][sub_df_cols]\n",
    "\n",
    "    df = pd.merge(sub_df, traffic_stations[traffic_stations[\"fips_state_code\"] == fips_state_code]\n",
    "                  [common_cols + spatial_cols], on=common_cols)\n",
    "    df[\"day_vol\"] = df[new_traffic_vol_cols].sum(axis=1).values\n",
    "\n",
    "    save_df_feather(df, save_dir, filename=fips_state_code)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_transformed_vol_df(station_id, sub_df=None, save_dir=None, verbose=True, overwrite=False):\n",
    "    file_path = f\"{os.path.join(save_dir, station_id)}.fea\"\n",
    "\n",
    "    if overwrite == False and os.path.isfile(file_path):\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"File already exists. Retrieving DataFrame from '{file_path}'.\")\n",
    "        processed_df = read_df_feather(save_dir, filename=station_id)\n",
    "        return processed_df\n",
    "\n",
    "    col_timestamp = \"date\"\n",
    "    col_trafficvol = \"traffic_volume\"\n",
    "\n",
    "    station_df = sub_df[sub_df[\"station_id\"]\n",
    "                        == station_id][historical_vol_cols]\n",
    "    sum_station_df = pd.DataFrame()\n",
    "    dates = list(station_df[col_timestamp].unique())\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Calculating total hourly volume collected per timestamp from station {station_id}.\")\n",
    "        iter = tqdm(dates)\n",
    "    else:\n",
    "        iter = dates\n",
    "    for date in iter:\n",
    "        date_condition = station_df[col_timestamp] == date\n",
    "        sum_df = station_df[date_condition].sum()\n",
    "        sum_df[col_timestamp] = date\n",
    "\n",
    "        sum_station_df = sum_station_df.append(sum_df, ignore_index=True)\n",
    "\n",
    "    row_idxs = range(0, sum_station_df.shape[0])\n",
    "    if verbose:\n",
    "        print(f\"Transforming DataFrame with hourly volume rows.\")\n",
    "        iter = tqdm(row_idxs)\n",
    "    else:\n",
    "        iter = row_idxs\n",
    "    dates = sum_station_df[col_timestamp].to_list()\n",
    "    hourly_volumes = sum_station_df[new_traffic_vol_cols].to_numpy()\n",
    "\n",
    "    all_volumes = []\n",
    "    timestamps = []\n",
    "\n",
    "    hour_delta = [np.timedelta64(hour, 'h') for hour in range(0, 24)]\n",
    "\n",
    "    for row_cnt in iter:\n",
    "        sub_timestamps = [dates[row_cnt] + hour for hour in hour_delta]\n",
    "        sub_vols = list(hourly_volumes[row_cnt])\n",
    "\n",
    "        timestamps += sub_timestamps\n",
    "        all_volumes += sub_vols\n",
    "\n",
    "    processed_df = pd.DataFrame()\n",
    "    processed_df[col_timestamp] = timestamps\n",
    "    processed_df[col_trafficvol] = all_volumes\n",
    "    processed_df = processed_df.sort_values(\n",
    "        by=[col_timestamp]).reset_index(drop=True)\n",
    "\n",
    "    if save_dir != None:\n",
    "        save_df_feather(df=processed_df,\n",
    "                        file_dir=save_dir,\n",
    "                        filename=station_id,\n",
    "                        verbose=verbose)\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def get_dataset_splits(df, test_count=61, datetime_unit=\"D\", ratio_split=False, temporal_split=True):\n",
    "    \"\"\"\n",
    "    test_count : 61 days for November (30 days) and December (31 days)\n",
    "    datetime_unit : \"D\" to indicate days\n",
    "    \"\"\"\n",
    "\n",
    "    col_timestamp = \"date\"\n",
    "\n",
    "    val_ratio = .15\n",
    "    test_ratio = .15\n",
    "    train_ratio = 1 - (test_ratio + val_ratio)\n",
    "\n",
    "    temporal_limit = df[col_timestamp].max(\n",
    "    ) - np.timedelta64(test_count, datetime_unit)\n",
    "\n",
    "    if temporal_split:\n",
    "        train_df = df[df[col_timestamp] <= temporal_limit]\n",
    "        val_df = None\n",
    "        test_df = df[df[col_timestamp] > temporal_limit]\n",
    "    elif ratio_split:\n",
    "        train_range = int(df.shape[0]*train_ratio)\n",
    "        val_range = int(df.shape[0]*val_ratio)\n",
    "\n",
    "        train_df = df.iloc[0:train_range]\n",
    "        val_df = df.iloc[train_range:train_range+val_range]\n",
    "        test_df = df.iloc[train_range+val_range:]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "# Based on:\n",
    "# - https://towardsdatascience.com/fast-and-robust-sliding-window-vectorization-with-numpy-3ad950ed62f5\n",
    "# - https://machinelearningmastery.com/xgboost-for-time-series-forecasting/\n",
    "\n",
    "def get_sliding_windows(array, max_time, sub_window_size, stride_size):\n",
    "    sub_windows = (\n",
    "        np.expand_dims(np.arange(sub_window_size), 0) +\n",
    "        np.expand_dims(np.arange(max_time + 1, step=stride_size), 0).T\n",
    "    )\n",
    "\n",
    "    array = array[sub_windows]\n",
    "    X_values = array[:-1, :]\n",
    "    \n",
    "    # Assumes first column is for traffic volumes\n",
    "    y_values = array[1:, -stride_size:,0]\n",
    "\n",
    "    return X_values, y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from:\n",
    "# https://stackoverflow.com/questions/22951956/most-efficient-way-to-create-an-array-of-cos-and-sin-in-numpy\n",
    "def get_sincos(arr):\n",
    "    theta = 2 * np.pi * arr\n",
    "    return np.vstack((np.sin(theta),\n",
    "                      np.cos(theta))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from:\n",
    "# - https://medium.com/@dan.allison/how-to-encode-the-cyclic-properties-of-time-with-python-6f4971d245c0\n",
    "# - https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning\n",
    "\n",
    "days_in_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "\n",
    "def sin_cos(n):\n",
    "    theta = 2 * pi * n\n",
    "    return (sin(theta), cos(theta))\n",
    "\n",
    "\n",
    "def get_cycles(df):\n",
    "    '''\n",
    "    Get the cyclic properties of a datetime,\n",
    "    represented as points on the unit circle.\n",
    "    '''\n",
    "\n",
    "    months = df[\"date\"].dt.month.to_numpy() - 1\n",
    "    days = df[\"date\"].dt.day.to_numpy() - 1\n",
    "    weekdays = df[\"date\"].dt.weekday.to_numpy()\n",
    "    hours = df[\"date\"].dt.hour.to_numpy()\n",
    "    \n",
    "    days_in_months = np.array([days_in_month[month] for month in months])\n",
    "    \n",
    "    month_cyc = get_sincos(months/12).T\n",
    "    day_cyc = get_sincos(days/days_in_months).T\n",
    "    weekday_cyc = get_sincos(weekdays / 7).T\n",
    "    hour_cyc = get_sincos(months/24).T\n",
    "\n",
    "    df[\"month_sin\"] = month_cyc[0]\n",
    "    df[\"month_cos\"] = month_cyc[1]\n",
    "    \n",
    "    df[\"day_sin\"] = day_cyc[0]\n",
    "    df[\"day_cos\"] = day_cyc[1]\n",
    "    \n",
    "    df[\"weekday_sin\"] = weekday_cyc[0]\n",
    "    df[\"weekday_cos\"] = weekday_cyc[1]\n",
    "    \n",
    "    df[\"hour_sin\"] = hour_cyc[0]\n",
    "    df[\"hour_cos\"] = hour_cyc[1]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2015-01-01\n",
       "1        2015-01-01\n",
       "2        2015-01-01\n",
       "3        2015-01-01\n",
       "4        2015-01-01\n",
       "            ...    \n",
       "191180   2015-12-31\n",
       "191181   2015-12-31\n",
       "191182   2015-12-31\n",
       "191183   2015-12-31\n",
       "191184   2015-12-31\n",
       "Name: date, Length: 191185, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_features(df, traffic_stations, station_id, fips_state_code):\n",
    "    cnt = df.shape[0]\n",
    "\n",
    "    # Temporal\n",
    "    df = get_cycles(df)\n",
    "    df[\"hour_of_day\"] = df[\"date\"].dt.hour\n",
    "    df.loc[(6 <= df[\"hour_of_day\"]) & (df[\"hour_of_day\"] < 12), \"part_of_day\"] = 1\n",
    "    df.loc[(12 <= df[\"hour_of_day\"]) & (df[\"hour_of_day\"] < 18), \"part_of_day\"] = 2\n",
    "    df.loc[(18 <= df[\"hour_of_day\"]), \"part_of_day\"] = 3\n",
    "    df[\"day_of_week\"] = df[\"date\"].dt.dayofweek\n",
    "    df.loc[df[\"day_of_week\"] <= 4, \"is_weekday\"] = 1 # True\n",
    "    df.loc[df[\"day_of_week\"] >= 5, \"is_weekday\"] = 0 # False\n",
    "    \n",
    "    # Can be added for DFs with hourly entries\n",
    "    df[\"hour_of_day\"] = df[\"date\"].dt.hour\n",
    "    df[\"part_of_day\"] = [0]*cnt\n",
    "    \n",
    "    sub_info = traffic_stations[(traffic_stations[\"station_id\"] == station_id) & \n",
    "                     (traffic_stations[\"fips_state_code\"] == fips_state_code)]\n",
    "    county_code = sub_info[\"fips_county_code\"].unique()[0]\n",
    "    \n",
    "    # Provides a combined string for encoding later\n",
    "    df[\"loc_info\"] = [f\"{station_id}-{fips_state_code}-county_code\"]*cnt\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'C:\\Users\\combi\\Documents\\gitrepos\\us-traffic\\src\\data\\processed' exists.\n"
     ]
    }
   ],
   "source": [
    "# Saves processed data under the data directory\n",
    "\n",
    "PROC_LOCATION = os.path.join(DATA_LOCATION, 'processed')\n",
    "datautils.create_folder(PROC_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this sample, 7 days prior are used as data input and\n",
    "# 1 day is forecasted (24 hrs)\n",
    "\n",
    "# In hours\n",
    "input_window_size = 24*7\n",
    "output_window_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['traffic_volume',\n",
    "                 'month_sin',\n",
    "                 'month_cos',\n",
    "                 'day_sin',\n",
    "                 'day_cos',\n",
    "                 'weekday_sin',\n",
    "                 'weekday_cos',\n",
    "                 'hour_sin',\n",
    "                 'hour_cos',\n",
    "                 'part_of_day',\n",
    "                 'loc_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>traffic_volume_counted_after_0000_to_0100</th>\n",
       "      <th>traffic_volume_counted_after_0100_to_0200</th>\n",
       "      <th>traffic_volume_counted_after_0200_to_0300</th>\n",
       "      <th>traffic_volume_counted_after_0300_to_0400</th>\n",
       "      <th>traffic_volume_counted_after_0400_to_0500</th>\n",
       "      <th>traffic_volume_counted_after_0500_to_0600</th>\n",
       "      <th>traffic_volume_counted_after_0600_to_0700</th>\n",
       "      <th>traffic_volume_counted_after_0700_to_0800</th>\n",
       "      <th>traffic_volume_counted_after_0800_to_0900</th>\n",
       "      <th>...</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>weekday_sin</th>\n",
       "      <th>weekday_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>part_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>loc_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>3838</td>\n",
       "      <td>4378</td>\n",
       "      <td>3177</td>\n",
       "      <td>1979</td>\n",
       "      <td>1547</td>\n",
       "      <td>2052</td>\n",
       "      <td>829</td>\n",
       "      <td>2378</td>\n",
       "      <td>2843</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>074870-6-county_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>72</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>074870-6-county_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>074870-6-county_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>462</td>\n",
       "      <td>365</td>\n",
       "      <td>258</td>\n",
       "      <td>176</td>\n",
       "      <td>159</td>\n",
       "      <td>228</td>\n",
       "      <td>369</td>\n",
       "      <td>542</td>\n",
       "      <td>723</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>074870-6-county_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>074870-6-county_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191180</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>155</td>\n",
       "      <td>103</td>\n",
       "      <td>94</td>\n",
       "      <td>82</td>\n",
       "      <td>193</td>\n",
       "      <td>551</td>\n",
       "      <td>651</td>\n",
       "      <td>652</td>\n",
       "      <td>598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>074870-6-county_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191181</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>074870-6-county_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191182</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>623</td>\n",
       "      <td>389</td>\n",
       "      <td>251</td>\n",
       "      <td>186</td>\n",
       "      <td>328</td>\n",
       "      <td>706</td>\n",
       "      <td>1570</td>\n",
       "      <td>2608</td>\n",
       "      <td>3249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>074870-6-county_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191183</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>696</td>\n",
       "      <td>566</td>\n",
       "      <td>431</td>\n",
       "      <td>414</td>\n",
       "      <td>660</td>\n",
       "      <td>1099</td>\n",
       "      <td>1535</td>\n",
       "      <td>1935</td>\n",
       "      <td>2129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>074870-6-county_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191184</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>074870-6-county_code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191185 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  traffic_volume_counted_after_0000_to_0100  \\\n",
       "0      2015-01-01                                       3838   \n",
       "1      2015-01-01                                         43   \n",
       "2      2015-01-01                                         64   \n",
       "3      2015-01-01                                        462   \n",
       "4      2015-01-01                                         60   \n",
       "...           ...                                        ...   \n",
       "191180 2015-12-31                                        155   \n",
       "191181 2015-12-31                                         25   \n",
       "191182 2015-12-31                                        623   \n",
       "191183 2015-12-31                                        696   \n",
       "191184 2015-12-31                                         31   \n",
       "\n",
       "        traffic_volume_counted_after_0100_to_0200  \\\n",
       "0                                            4378   \n",
       "1                                              54   \n",
       "2                                              54   \n",
       "3                                             365   \n",
       "4                                              32   \n",
       "...                                           ...   \n",
       "191180                                        103   \n",
       "191181                                         20   \n",
       "191182                                        389   \n",
       "191183                                        566   \n",
       "191184                                         32   \n",
       "\n",
       "        traffic_volume_counted_after_0200_to_0300  \\\n",
       "0                                            3177   \n",
       "1                                              57   \n",
       "2                                              31   \n",
       "3                                             258   \n",
       "4                                              21   \n",
       "...                                           ...   \n",
       "191180                                         94   \n",
       "191181                                          4   \n",
       "191182                                        251   \n",
       "191183                                        431   \n",
       "191184                                         28   \n",
       "\n",
       "        traffic_volume_counted_after_0300_to_0400  \\\n",
       "0                                            1979   \n",
       "1                                              31   \n",
       "2                                              24   \n",
       "3                                             176   \n",
       "4                                               9   \n",
       "...                                           ...   \n",
       "191180                                         82   \n",
       "191181                                          2   \n",
       "191182                                        186   \n",
       "191183                                        414   \n",
       "191184                                         14   \n",
       "\n",
       "        traffic_volume_counted_after_0400_to_0500  \\\n",
       "0                                            1547   \n",
       "1                                              27   \n",
       "2                                              23   \n",
       "3                                             159   \n",
       "4                                              13   \n",
       "...                                           ...   \n",
       "191180                                        193   \n",
       "191181                                          3   \n",
       "191182                                        328   \n",
       "191183                                        660   \n",
       "191184                                         19   \n",
       "\n",
       "        traffic_volume_counted_after_0500_to_0600  \\\n",
       "0                                            2052   \n",
       "1                                              38   \n",
       "2                                              46   \n",
       "3                                             228   \n",
       "4                                              14   \n",
       "...                                           ...   \n",
       "191180                                        551   \n",
       "191181                                          4   \n",
       "191182                                        706   \n",
       "191183                                       1099   \n",
       "191184                                         25   \n",
       "\n",
       "        traffic_volume_counted_after_0600_to_0700  \\\n",
       "0                                             829   \n",
       "1                                              39   \n",
       "2                                              48   \n",
       "3                                             369   \n",
       "4                                              26   \n",
       "...                                           ...   \n",
       "191180                                        651   \n",
       "191181                                         13   \n",
       "191182                                       1570   \n",
       "191183                                       1535   \n",
       "191184                                         56   \n",
       "\n",
       "        traffic_volume_counted_after_0700_to_0800  \\\n",
       "0                                            2378   \n",
       "1                                              72   \n",
       "2                                              64   \n",
       "3                                             542   \n",
       "4                                              35   \n",
       "...                                           ...   \n",
       "191180                                        652   \n",
       "191181                                         29   \n",
       "191182                                       2608   \n",
       "191183                                       1935   \n",
       "191184                                        158   \n",
       "\n",
       "        traffic_volume_counted_after_0800_to_0900  ...  day_cos  weekday_sin  \\\n",
       "0                                            2843  ...  1.00000     0.433884   \n",
       "1                                             100  ...  1.00000     0.433884   \n",
       "2                                             109  ...  1.00000     0.433884   \n",
       "3                                             723  ...  1.00000     0.433884   \n",
       "4                                              91  ...  1.00000     0.433884   \n",
       "...                                           ...  ...      ...          ...   \n",
       "191180                                        598  ...  0.97953     0.433884   \n",
       "191181                                        147  ...  0.97953     0.433884   \n",
       "191182                                       3249  ...  0.97953     0.433884   \n",
       "191183                                       2129  ...  0.97953     0.433884   \n",
       "191184                                        159  ...  0.97953     0.433884   \n",
       "\n",
       "        weekday_cos  hour_sin  hour_cos  hour_of_day  part_of_day  \\\n",
       "0         -0.900969  0.000000  1.000000            0            0   \n",
       "1         -0.900969  0.000000  1.000000            0            0   \n",
       "2         -0.900969  0.000000  1.000000            0            0   \n",
       "3         -0.900969  0.000000  1.000000            0            0   \n",
       "4         -0.900969  0.000000  1.000000            0            0   \n",
       "...             ...       ...       ...          ...          ...   \n",
       "191180    -0.900969  0.258819 -0.965926            0            0   \n",
       "191181    -0.900969  0.258819 -0.965926            0            0   \n",
       "191182    -0.900969  0.258819 -0.965926            0            0   \n",
       "191183    -0.900969  0.258819 -0.965926            0            0   \n",
       "191184    -0.900969  0.258819 -0.965926            0            0   \n",
       "\n",
       "        day_of_week  is_weekday              loc_info  \n",
       "0                 3         1.0  074870-6-county_code  \n",
       "1                 3         1.0  074870-6-county_code  \n",
       "2                 3         1.0  074870-6-county_code  \n",
       "3                 3         1.0  074870-6-county_code  \n",
       "4                 3         1.0  074870-6-county_code  \n",
       "...             ...         ...                   ...  \n",
       "191180            3         1.0  074870-6-county_code  \n",
       "191181            3         1.0  074870-6-county_code  \n",
       "191182            3         1.0  074870-6-county_code  \n",
       "191183            3         1.0  074870-6-county_code  \n",
       "191184            3         1.0  074870-6-county_code  \n",
       "\n",
       "[191185 rows x 47 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_other_features(sub_df, sub_df, \"074870\", fips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Guide for using pre-processed data as input (LSTM)\n",
    "\n",
    "For this section, the guide shows a sample for using the data as input to an LSTM model. The code blocks are commented out as they require pre-processed data which is provided as an output by *preprocess_trafficdata.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of setting it as 24 immediately, we can prepare the model to prepare\n",
    "# predictions and take as input the forecasted value from the previous timestamps\n",
    "\n",
    "# In hours\n",
    "input_window_size = 24*7\n",
    "output_window_size = 24\n",
    "\n",
    "# Selected sample features\n",
    "feature_cols = ['traffic_volume',\n",
    "                 'month_sin',\n",
    "                 'month_cos',\n",
    "                 'day_sin',\n",
    "                 'day_cos',\n",
    "                 'weekday_sin',\n",
    "                 'weekday_cos',\n",
    "                 'hour_sin',\n",
    "                 'hour_cos',\n",
    "                 'part_of_day',\n",
    "                 'loc_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires further optimization\n",
    "\n",
    "# MODEL_LOCATION = os.path.join(os.getcwd(), 'models')\n",
    "# create_folder(MODEL_LOCATION)\n",
    "\n",
    "# codes = [6] #12, 29, 28, 51, 39, 13, 55, 53, 16, 36, 40, 28, 29]\n",
    "# verbose = False\n",
    "\n",
    "# X_train = np.empty((0, input_window_size, len(feature_cols)))\n",
    "# y_train = np.empty((0, output_window_size))\n",
    "\n",
    "# X_test = np.empty((0, input_window_size, len(feature_cols)))\n",
    "# y_test = np.empty((0, output_window_size))\n",
    "\n",
    "# for fips_state_code in tqdm(codes):\n",
    "#     model_input_dir = os.path.join(processed_dir, str(fips_state_code))\n",
    "#     create_folder(model_input_dir)\n",
    "\n",
    "#     station_ids = [x.split('.')[0] for x in os.listdir(model_input_dir)]\n",
    "\n",
    "#     for station_id in tqdm(station_ids):\n",
    "#         processed_df = get_transformed_vol_df(station_id,\n",
    "#                                                           save_dir=model_input_dir,\n",
    "#                                                           verbose=verbose)\n",
    "#         train_df, _, test_df = get_dataset_splits(processed_df)\n",
    "\n",
    "#         train_df = get_other_features(train_df, \n",
    "#                                        traffic_stations, \n",
    "#                                        station_id, \n",
    "#                                        fips_state_code)\n",
    "\n",
    "#         arr = train_df[feature_cols].to_numpy()\n",
    "#         sub_X_train, sub_y_train = get_sliding_windows(array=arr,\n",
    "#                                                       max_time=arr.shape[0]-input_window_size,\n",
    "#                                                       sub_window_size=input_window_size,\n",
    "#                                                       stride_size=output_window_size)\n",
    "\n",
    "#         X_train = np.append(X_train, sub_X_train, axis=0)\n",
    "#         y_train = np.append(y_train, sub_y_train, axis=0)\n",
    "\n",
    "#         test_df = get_other_features(test_df, \n",
    "#                                        traffic_stations, \n",
    "#                                        station_id, \n",
    "#                                        fips_state_code)\n",
    "#         arr = test_df[feature_cols].to_numpy()\n",
    "#         sub_X_test, sub_y_test = get_sliding_windows(array=arr,\n",
    "#                                   max_time=arr.shape[0]-input_window_size,\n",
    "#                                   sub_window_size=input_window_size,\n",
    "#                                   stride_size=output_window_size)\n",
    "\n",
    "#         X_test = np.append(X_test, sub_X_test, axis=0)\n",
    "#         y_test = np.append(y_test, sub_y_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class dataset is also provided with additional functions and configurations. For this case, it takes as input historical traffic volume per hour for a range of 7 days and provides a forecast of 1 day with 24 data points (hourly). It also takes as input the part of day, and combined location features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    # Use class instead of multiple returns\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, locations):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train.astype('float32')\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test.astype('float32')\n",
    "        self.day_count = 7\n",
    "        self.hour_interval = 6\n",
    "        self.hour_ranges = range(0, 24, self.hour_interval)\n",
    "\n",
    "        self.X_val = None\n",
    "        self.y_val = None\n",
    "\n",
    "        # Station IDs\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(locations)\n",
    "\n",
    "        self.input_window_size = 24*7\n",
    "        self.output_window_size = 24\n",
    "\n",
    "    def get_split_input(self, X_values):\n",
    "        # Traffic volume\n",
    "        traffic_vols = np.asarray(X_values[:,:,0]).astype('float32')\n",
    "        traffic_vols = traffic_vols.reshape(-1, self.input_window_size, 1)\n",
    "\n",
    "        # Temporal features (cyclical timestamps)\n",
    "        cyclical_timestamps = X_values[:,:,1:-2].reshape(-1, self.input_window_size*8, 1)\n",
    "        cyclical_timestamps = np.asarray(cyclical_timestamps).astype('float32') \n",
    "\n",
    "        # Part of day\n",
    "        part_of_day = X_values[:,:,-2:-1].astype(int)\n",
    "\n",
    "        # Location feature\n",
    "        encoded_locs = self.le.transform(X_values[:,:,-1:].reshape(-1))\n",
    "        encoded_locs = encoded_locs.reshape(-1, self.input_window_size, 1).astype(int)\n",
    "\n",
    "        return [traffic_vols,\n",
    "                cyclical_timestamps,\n",
    "                part_of_day,\n",
    "                encoded_locs]\n",
    "\n",
    "    def create_validation_set(self, val_ratio=0.10):\n",
    "        # Retrieve random indices for validation and train\n",
    "        train_len = self.X_train.shape[0]\n",
    "        val_len = int(train_len*val_ratio)\n",
    "        val_idxs = random.sample(range(0, train_len), val_len)\n",
    "        train_idxs = list(set(range(0, train_len)) - set(val_idxs))\n",
    "\n",
    "        # Retrieve new length\n",
    "        train_len = len(train_idxs)\n",
    "\n",
    "        # Modify val before original\n",
    "        self.X_val = self.X_train[val_idxs]\n",
    "        self.X_train = self.X_train[train_idxs]\n",
    "\n",
    "        self.y_val = self.y_train[val_idxs]\n",
    "        self.y_train = self.y_train[train_idxs]\n",
    "\n",
    "\n",
    "    def get_reshaped_splits(self, get_val=True):\n",
    "        if get_val == True:\n",
    "            create_validation_set()\n",
    "            # Reshape validation input\n",
    "            self.X_val = self.X_val.reshape(val_len,-1,self.day_count)\n",
    "        train_len = self.X_train.shape[0]\n",
    "        test_len = self.X_test.shape[0]\n",
    "        # Reshape test and train input\n",
    "        self.X_train = self.X_train.reshape(train_len,-1,self.day_count)\n",
    "        self.X_test = self.X_test.reshape(test_len,-1,self.day_count)\n",
    "\n",
    "\n",
    "    def get_sub_y(self, y_values, part_of_day):\n",
    "        # [0:6) - midnight to morning\n",
    "        # [6:12) - morning to afternoon\n",
    "        # [12:18) - afternoon to night\n",
    "        # [18:23] - night to midnight\n",
    "\n",
    "        hour_idx = self.hour_ranges[part_of_day]\n",
    "        y_sub = y_values[:, hour_idx:hour_idx+self.hour_interval]\n",
    "        \n",
    "        return y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_locs = np.unique(X_train[:,:,-1:])\n",
    "\n",
    "# data = Dataset(X_train, y_train,\n",
    "#                X_test, y_test,\n",
    "#                all_locs)\n",
    "# data.create_validation_set()\n",
    "# X_train_split = data.get_split_input(data.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.layers import Input, Embedding, Flatten, BatchNormalization, \\\n",
    "#                                     Concatenate, Reshape, Dense, LSTM, Dropout\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "# import tensorflow.keras.backend as K\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def rmse(y_true, y_pred):\n",
    "#     return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sample LSTM model used to forecast 24 hours of traffic volume for a given day. Still a work in a progress as the RMSE values for this model is still relatively high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras.models as M\n",
    "\n",
    "# def get_lstm_model(model_input, all_locs, checkpt_path):\n",
    "\n",
    "#     SINCOS_FEATS = 8 # Month, Day, Weekday, Hour\n",
    "#     VOL_FEATS = 1\n",
    "#     PARTS_OF_DAY = 4\n",
    "#     LOOKBACK_SIZE = 24*7\n",
    "#     FORECAST_PERIOD = 24 # in hours\n",
    "#     LOC_CNT = len(all_locs)\n",
    "\n",
    "#     input_dim = LOOKBACK_SIZE\n",
    "\n",
    "#     # Traffic Volume\n",
    "#     input_vol_layer = Input(input_dim, )\n",
    "#     x1 = BatchNormalization()(input_vol_layer)\n",
    "#     x1 = Dense(VOL_FEATS * 128, activation='selu')(x1)\n",
    "\n",
    "#     # SinCos Temporal Features\n",
    "#     input_time_layer = Input(shape=(input_dim*SINCOS_FEATS,))\n",
    "#     x2 = BatchNormalization()(input_time_layer, )\n",
    "#     x2 = Dense(SINCOS_FEATS*64, activation='selu')(x2)\n",
    "\n",
    "#     # Part of Day\n",
    "#     input_pod_layer = Input(shape=(input_dim,))\n",
    "#     x3 = Embedding(PARTS_OF_DAY, 2)(input_pod_layer)\n",
    "#     x3 = Flatten()(x3)\n",
    "\n",
    "#     # Station ID\n",
    "#     input_location_layer = Input(shape=(input_dim,))\n",
    "#     x4 = Embedding(LOC_CNT, 2)(input_location_layer)\n",
    "#     x4 = Flatten()(x4)\n",
    "\n",
    "#     # main stream\n",
    "#     x = Concatenate(axis=1)([x1, x2, x3, x4])\n",
    "\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense(1024, activation='selu')(x)\n",
    "\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense(512, activation='selu')(x)\n",
    "\n",
    "#     x = Reshape((1, -1))(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LSTM(512, dropout=0.4, recurrent_dropout=0.2, \n",
    "#              return_sequences=True, activation='selu')(x)\n",
    "#     x = LSTM(256, dropout=0.2, recurrent_dropout=0.2, \n",
    "#     return_sequences=True, activation='selu')(x)\n",
    "#     x = LSTM(128, dropout=0.1, return_sequences=False, \n",
    "#              activation='selu')(x)\n",
    "\n",
    "#     output_layer = Dense(FORECAST_PERIOD, name=\"trafficvolume\")(x)\n",
    "\n",
    "#     model = M.Model([input_vol_layer,\n",
    "#                      input_time_layer,\n",
    "#                      input_pod_layer,\n",
    "#                      input_location_layer], \n",
    "#                     [output_layer])\n",
    "\n",
    "\n",
    "#     rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "#     model.compile(loss=rmse, optimizer=rmsprop, metrics=[rmse])\n",
    "\n",
    "#     callbacks = [ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                    factor=0.1, patience=3, \n",
    "#                                    verbose=1, min_delta=1e-4, mode='min'),\n",
    "#                  ModelCheckpoint(checkpt_path, \n",
    "#                                  monitor='val_loss', verbose=0, \n",
    "#                                  save_best_only=True, save_weights_only=True, mode='min'),\n",
    "#                  EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, mode='min',\n",
    "#                                baseline=None, restore_best_weights=True)\n",
    "#             ]\n",
    "\n",
    "#     return model, callbacks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
