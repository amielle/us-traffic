{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. Experimentation with FLAML",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c7CnjEN1hRx"
      },
      "source": [
        "# 4. Experimentation with FLAML\n",
        "\n",
        "Additionally, [FLAML](https://github.com/microsoft/FLAML), a lightweight tool for retrieving parameters for models was also explored. However, upon use the parameters are somewhat unreliable given the forecast period and the corresponding RMSE results. Code blocks were commented out for clarity of the notebook and more exploration was done across other tests but tweaked parameters still performed better than parameters provided by FLAML. Although it may be good for other tasks, the time restrictions for the given exploration makes it difficult to explore this further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pvirUJcYGPa",
        "outputId": "bd2c737b-f4ee-4c08-d6f6-890a6703f380"
      },
      "source": [
        "!pip install gdown numpy pandas sklearn matplotlib lightgbm reverse_geocoder folium selenium flaml pystan==2.19.1.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Collecting reverse_geocoder\n",
            "  Downloading reverse_geocoder-1.5.1.tar.gz (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: folium in /usr/local/lib/python3.7/dist-packages (0.8.3)\n",
            "Collecting selenium\n",
            "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
            "\u001b[K     |████████████████████████████████| 904 kB 43.8 MB/s \n",
            "\u001b[?25hCollecting flaml\n",
            "  Downloading FLAML-0.6.3-py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pystan==2.19.1.1 in /usr/local/lib/python3.7/dist-packages (2.19.1.1)\n",
            "Requirement already satisfied: Cython!=0.25.1,>=0.22 in /usr/local/lib/python3.7/dist-packages (from pystan==2.19.1.1) (0.29.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from folium) (2.11.3)\n",
            "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium) (0.4.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Collecting catboost>=0.23\n",
            "  Downloading catboost-0.26.1-cp37-none-manylinux1_x86_64.whl (67.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 67.4 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml) (0.90)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting lightgbm\n",
            "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 18.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.37.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (0.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->folium) (2.0.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.23->flaml) (1.3.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Building wheels for collected packages: reverse-geocoder\n",
            "  Building wheel for reverse-geocoder (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for reverse-geocoder: filename=reverse_geocoder-1.5.1-py3-none-any.whl size=2268087 sha256=29a47339484692c0a38adaf01406812c26f131a71a54375356a58deb209df52e\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/6e/70/5423639428a2cac8ea7eb467214a4254b549b381f306a9c790\n",
            "Successfully built reverse-geocoder\n",
            "Installing collected packages: threadpoolctl, scikit-learn, lightgbm, catboost, selenium, reverse-geocoder, flaml\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed catboost-0.26.1 flaml-0.6.3 lightgbm-3.2.1 reverse-geocoder-1.5.1 scikit-learn-0.24.2 selenium-3.141.0 threadpoolctl-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbmS9-0hrEz-",
        "outputId": "4079ce2a-56ea-47af-fb91-e834d8583c2a"
      },
      "source": [
        "!pip install prophet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting prophet\n",
            "  Downloading prophet-1.0.1.tar.gz (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.29.24)\n",
            "Collecting cmdstanpy==0.9.68\n",
            "  Downloading cmdstanpy-0.9.68-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pystan~=2.19.1.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.19.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (3.2.2)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.0.9)\n",
            "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.3.2)\n",
            "Requirement already satisfied: holidays>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.10.5.2)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (4.62.0)\n",
            "Collecting ujson\n",
            "  Downloading ujson-4.1.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.1.2->prophet) (2018.9)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.1.2->prophet) (0.5.11)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (1.15.0)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (0.2.1)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (2.1.3)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->prophet) (4.0.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.1)\n",
            "Building wheels for collected packages: prophet\n",
            "  Building wheel for prophet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prophet: filename=prophet-1.0.1-py3-none-any.whl size=6640907 sha256=3c2bc8258f4de60e7581b06d7235896bcd80a6108142637d220566a1de27213d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/a0/1a/02c9ec9e3e9de6bdbb3d769d11992a6926889d71567d6b9b67\n",
            "Successfully built prophet\n",
            "Installing collected packages: ujson, cmdstanpy, prophet\n",
            "  Attempting uninstall: cmdstanpy\n",
            "    Found existing installation: cmdstanpy 0.9.5\n",
            "    Uninstalling cmdstanpy-0.9.5:\n",
            "      Successfully uninstalled cmdstanpy-0.9.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fbprophet 0.7.1 requires cmdstanpy==0.9.5, but you have cmdstanpy 0.9.68 which is incompatible.\u001b[0m\n",
            "Successfully installed cmdstanpy-0.9.68 prophet-1.0.1 ujson-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp2CpWrAYGPd"
      },
      "source": [
        "import datetime as dt\n",
        "import array\n",
        "\n",
        "import gdown\n",
        "import reverse_geocoder\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import pickle\n",
        "import math"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODZDpYPatXte"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBp3PzAhYGPf"
      },
      "source": [
        "filenames = {\n",
        "    \"TRAFFIC_DATA\" : \"dot_traffic_2015.txt.gz\",\n",
        "    \"TRAFFIC_STATIONS\" : \"dot_traffic_stations_2015.txt.gz\",\n",
        "    \"FIPS_CODE\" : \"fips_code.csv\"\n",
        "}\n",
        "\n",
        "IS_FROM_GDRIVE = True\n",
        "\n",
        "urls = {\n",
        "    \"TRAFFIC_DATA\" : \"https://drive.google.com/file/d/18I43wccnq-e0bo238oarO4a-8C6xHGvT/view?usp=sharing\",\n",
        "    \"TRAFFIC_STATIONS\" : \"https://drive.google.com/file/d/1xGOS1qL-K7mmqgTGEoQPRI2j7IpSRYX_/view?usp=sharing\",\n",
        "    \"FIPS_CODE\" : \"https://drive.google.com/file/d/1se0opJXSO90W8nesCVCDqJ7k6i9f_WEu/view?usp=sharing\"\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9pM6h_vYGPg"
      },
      "source": [
        "def create_folder(DIR):\n",
        "    if not os.path.isdir(DIR):\n",
        "        os.makedirs(DIR)\n",
        "        print(f\"Created folder '{DIR}' .\")\n",
        "    else:\n",
        "        print(f\"Folder '{DIR}' exists.\")\n",
        "\n",
        "def gdrive_download(url, filename):\n",
        "    url_id = url.split(\"/\")[5]\n",
        "    dl_url = f\"https://drive.google.com/uc?id={url_id}\"\n",
        "    gdown.download(dl_url, filename, quiet=False)\n",
        "\n",
        "def load_txtgz(DATA_LOCATION, FILE):\n",
        "    df = pd.read_csv(os.path.join(DATA_LOCATION,FILE),\n",
        "                    header=0,\n",
        "                    sep=',',\n",
        "                    quotechar='\"')\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_traffic_datasets(DATA_LOCATION, TRAFFIC_DATA_FILE, \n",
        "                          TRAFFIC_STATIONS_FILE):\n",
        "    \"\"\"\n",
        "        Loads data contained in the files to DataFrames\n",
        "    \"\"\"\n",
        "    print(f\"Loading traffic data from '{TRAFFIC_DATA_FILE}' ...\")\n",
        "    traffic_data = load_txtgz(DATA_LOCATION, TRAFFIC_DATA_FILE)\n",
        "\n",
        "    print(f\"Loading traffic stations from '{TRAFFIC_STATIONS_FILE}' ...\")\n",
        "    traffic_stations = load_txtgz(DATA_LOCATION, TRAFFIC_STATIONS_FILE)\n",
        "\n",
        "    print(\"Finished loading data.\")\n",
        "    return traffic_data, traffic_stations\n",
        "\n",
        "def create_fips_ref(fips_df):\n",
        "    \"\"\"\n",
        "        Sets all the state names in the fips_df to lowercase for easier \n",
        "        comparisons and makes a dict reference with the FIPS code as \n",
        "        the key to shorten code instead of having to match/query the \n",
        "        DataFrame repeatedly.\n",
        "    \"\"\"\n",
        "    fips_state_ref = dict(zip(fips_df[\"fips_code\"],\n",
        "                            [x.lower() for x in fips_df[\"state_name\"]]))\n",
        "\n",
        "    return fips_state_ref"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CykmmKbyYGPl"
      },
      "source": [
        "common_cols = [\"direction_of_travel\",\n",
        "               \"fips_state_code\",\n",
        "               \"functional_classification\",\n",
        "               \"lane_of_travel\",\n",
        "               \"station_id\"]\n",
        "temporal_cols = [\"date\", \"day_of_data\",\n",
        "                \"day_of_week\", \"month_of_data\",\n",
        "                \"year_of_data\"]\n",
        "spatial_cols = [\"fips_county_code\", \"latitude\", \"longitude\"]\n",
        "new_traffic_vol_cols = [str(x) for x in range(0, 24)]\n",
        "subdf_cols = temporal_cols + new_traffic_vol_cols + common_cols\n",
        "historical_vol_cols = [\"date\"] + new_traffic_vol_cols\n",
        "\n",
        "\n",
        "def get_new_vol_cols(traffic_data):\n",
        "    traffic_vol_cols = [word for word in traffic_data.columns if 'traffic_volume_counted' in word]\n",
        "    traffic_data.rename(columns=dict(zip(traffic_vol_cols,\n",
        "                                     new_traffic_vol_cols)), inplace=True)\n",
        "    \n",
        "    return traffic_data\n",
        "\n",
        "\n",
        "def modify_temporal_cols(traffic_data):\n",
        "    traffic_data[\"date\"] = pd.to_datetime(traffic_data[\"date\"], format='%Y-%m-%d')\n",
        "    traffic_data = get_new_vol_cols(traffic_data)\n",
        "    traffic_data.loc[traffic_data[\"day_of_week\"] == 1, \"day_of_week\"] = 8\n",
        "    traffic_data[\"day_of_week\"] -= 2\n",
        "\n",
        "    return traffic_data\n",
        "\n",
        "\n",
        "def get_filtered_df(traffic_data, traffic_stations, fips_state_code, save_dir, overwrite=False):\n",
        "    file_path = f\"{os.path.join(processed_dir, str(fips_state_code))}.pkl\"\n",
        "\n",
        "    if overwrite == False and os.path.isfile(file_path):\n",
        "        print(f\"File already exists. Retrieving DataFrame from '{file_path}'.\")\n",
        "        with open(file_path, 'rb') as f:\n",
        "            df = pickle.load(f)\n",
        "        return df\n",
        "\n",
        "    subdf_cols = temporal_cols + new_traffic_vol_cols + common_cols\n",
        "    subdf = traffic_data[traffic_data[\"fips_state_code\"] == fips_state_code][subdf_cols]\n",
        "\n",
        "    df = pd.merge(subdf, traffic_stations[traffic_stations[\"fips_state_code\"] == fips_state_code]\n",
        "                                      [common_cols + spatial_cols], on=common_cols)\n",
        "    df[\"day_vol\"] = df[new_traffic_vol_cols].sum(axis=1).values\n",
        "\n",
        "    print(f\"Saving DataFrame to '{file_path}'.\")\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(df, f)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jbayqGv4n7H"
      },
      "source": [
        "def save_df_feather(df, dir, filename, verbose=True):\n",
        "    file_path = os.path.join(dir, f\"{filename}.fea\")\n",
        "    df.to_feather(file_path)\n",
        "    if verbose:\n",
        "        print(f\"Saved file {file_path}\")\n",
        "\n",
        "\n",
        "def read_df_feather(dir, filename):\n",
        "    file_path = os.path.join(dir, f\"{filename}.fea\")\n",
        "    df = pd.read_feather(file_path, use_threads=True)\n",
        "    return df"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN0HQqOZd3s_"
      },
      "source": [
        "def get_transformed_vol_df(subdf, station_id, dir=None, verbose=True, overwrite=False):\n",
        "    file_path = f\"{os.path.join(dir, station_id)}.fea\"\n",
        "\n",
        "    if overwrite == False and os.path.isfile(file_path):\n",
        "        if verbose:\n",
        "            print(f\"File already exists. Retrieving DataFrame from '{file_path}'.\")\n",
        "        subdf = read_df_feather(dir, filename=station_id)\n",
        "        return subdf\n",
        "\n",
        "    col_timestamp = \"date\"\n",
        "    col_trafficvol = \"traffic_volume\"\n",
        "\n",
        "    station_df = sub_df[sub_df[\"station_id\"] == station_id][historical_vol_cols]\n",
        "    sum_station_df = pd.DataFrame()\n",
        "    dates = list(station_df[col_timestamp].unique())\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Calculating total hourly volume collected per timestamp from station {station_id}.\")\n",
        "        iter = tqdm(dates)\n",
        "    else:\n",
        "        iter = dates\n",
        "    for date in iter:\n",
        "        date_condition = station_df[col_timestamp] == date\n",
        "        sum_df = station_df[date_condition].sum()\n",
        "        sum_df[col_timestamp] = date\n",
        "\n",
        "        sum_station_df = sum_station_df.append(sum_df, ignore_index = True)\n",
        "\n",
        "    row_idxs = range(0, sum_station_df.shape[0])\n",
        "    if verbose:\n",
        "        print(f\"Transforming DataFrame with hourly volume rows.\")\n",
        "        iter = tqdm(row_idxs)\n",
        "    else:\n",
        "        iter = row_idxs\n",
        "    dates = sum_station_df[col_timestamp].to_list()\n",
        "    hourly_volumes = sum_station_df[new_traffic_vol_cols].to_numpy()\n",
        "\n",
        "    all_volumes = []\n",
        "    timestamps = []\n",
        "\n",
        "    hour_delta = [np.timedelta64(hour, 'h') for hour in range(0,24)]\n",
        "\n",
        "    for row_cnt in iter:\n",
        "        sub_timestamps = [dates[row_cnt] + hour for hour in hour_delta]\n",
        "        sub_vols = list(hourly_volumes[row_cnt])\n",
        "\n",
        "        timestamps += sub_timestamps\n",
        "        all_volumes += sub_vols\n",
        "\n",
        "    processed_df = pd.DataFrame()\n",
        "    processed_df[col_timestamp] = timestamps\n",
        "    processed_df[col_trafficvol] = all_volumes\n",
        "    processed_df = processed_df.sort_values(by=[col_timestamp]).reset_index(drop=True)\n",
        "\n",
        "    if dir != None:\n",
        "        save_df_feather(df=processed_df,\n",
        "                        dir=dir,\n",
        "                        filename=station_id,\n",
        "                        verbose=verbose)\n",
        "\n",
        "    return processed_df\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S5EU8Y4YGPt"
      },
      "source": [
        "def get_dataset_splits(df, test_count=61, datetime_unit=\"D\", ratio_split=False, temporal_split=True):\n",
        "    \"\"\"\n",
        "    test_count : 61 days for November (30 days) and December (31 days)\n",
        "    datetime_unit : \"D\" to indicate days\n",
        "    \"\"\"\n",
        "\n",
        "    col_timestamp = \"date\"\n",
        "\n",
        "    val_ratio = .15\n",
        "    test_ratio = .15\n",
        "    train_ratio = 1 - (test_ratio + val_ratio)\n",
        "    \n",
        "    temporal_limit = df[col_timestamp].max() - np.timedelta64(test_count, datetime_unit)\n",
        "\n",
        "    if temporal_split:\n",
        "        train_df = df[df[col_timestamp] <= temporal_limit]\n",
        "        val_df = None\n",
        "        test_df = df[df[col_timestamp] > temporal_limit]\n",
        "    elif ratio_split:\n",
        "        train_range = int(df.shape[0]*train_ratio)\n",
        "        val_range = int(df.shape[0]*val_ratio)\n",
        "\n",
        "        train_df = df.iloc[0:train_range]\n",
        "        val_df = df.iloc[train_range:train_range+val_range]\n",
        "        test_df = df.iloc[train_range+val_range:]\n",
        "        \n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "def get_sliding_windows(array, max_time, sub_window_size, stride_size):\n",
        "    sub_windows = (\n",
        "        np.expand_dims(np.arange(sub_window_size), 0) +\n",
        "        np.expand_dims(np.arange(max_time + 1, step=stride_size), 0).T\n",
        "    )\n",
        "\n",
        "    array = array[sub_windows]\n",
        "    X_values = array[:-1, :]\n",
        "    \n",
        "    # Assumes first column is for traffic volumes\n",
        "    y_values = array[1:, -stride_size:,0]\n",
        "\n",
        "    return X_values, y_values"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntbajaJ-YGPi"
      },
      "source": [
        "DATA_LOCATION = os.getcwd()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr63jiDtayIe",
        "outputId": "e9fca7af-1bf0-49e3-a3e7-8600dfa5897a"
      },
      "source": [
        "for name in urls:\n",
        "    gdrive_download(urls[name], filenames[name])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18I43wccnq-e0bo238oarO4a-8C6xHGvT\n",
            "To: /content/dot_traffic_2015.txt.gz\n",
            "465MB [00:03, 118MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xGOS1qL-K7mmqgTGEoQPRI2j7IpSRYX_\n",
            "To: /content/dot_traffic_stations_2015.txt.gz\n",
            "2.26MB [00:00, 117MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1se0opJXSO90W8nesCVCDqJ7k6i9f_WEu\n",
            "To: /content/fips_code.csv\n",
            "100%|██████████| 918/918 [00:00<00:00, 976kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJI07OVpYGPi",
        "outputId": "ace0bb10-1642-4aa5-f3b3-66a188647f05"
      },
      "source": [
        "traffic_data, traffic_stations = load_traffic_datasets(DATA_LOCATION,\n",
        "                                                        filenames[\"TRAFFIC_DATA\"],\n",
        "                                                        filenames[\"TRAFFIC_STATIONS\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading traffic data from 'dot_traffic_2015.txt.gz' ...\n",
            "Loading traffic stations from 'dot_traffic_stations_2015.txt.gz' ...\n",
            "Finished loading data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV1GkHQfsDhd"
      },
      "source": [
        "traffic_data = get_new_vol_cols(traffic_data)\n",
        "traffic_data = modify_temporal_cols(traffic_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0AJ_p8pYGPk",
        "outputId": "29dbaacb-3192-4bbf-c51f-2ddf3a5e1f52"
      },
      "source": [
        "processed_dir = os.path.join(os.getcwd(), \"processed\")\n",
        "create_folder(processed_dir)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created folder '/content/processed' .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8yTNMnHcvpZ"
      },
      "source": [
        "fips_state_code = 6"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps0qtvov3qe0"
      },
      "source": [
        "# verbose = False\n",
        "\n",
        "# sub_df = get_filtered_df(traffic_data, \n",
        "#                         traffic_stations, \n",
        "#                         fips_state_code = fips_state_code,\n",
        "#                         save_dir = processed_dir)\n",
        "# model_input_dir = os.path.join(processed_dir, str(fips_state_code))\n",
        "# create_folder(model_input_dir)\n",
        "\n",
        "# for station_id in tqdm(sub_df[\"station_id\"].unique()):\n",
        "\n",
        "#     processed_df = get_transformed_vol_df(sub_df,\n",
        "#                                           station_id,\n",
        "#                                           dir=model_input_dir,\n",
        "#                                           verbose=verbose)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB5mHK66xsWF"
      },
      "source": [
        "Since runtime in colab is relatively slow for this task, we can choose to upload a preprocessed tar file as shown here. It can be dragged and dropped on the side panel where the other files in the colab notebook are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy7cIXqg8pD1",
        "outputId": "e63bc8b1-0efa-49fe-a6ac-0d1d464c8df3"
      },
      "source": [
        "!tar cvzf 6.tar.gz /content/processed/6"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: Removing leading `/' from member names\n",
            "/content/processed/6/\n",
            "/content/processed/6/075450.fea\n",
            "/content/processed/6/072130.fea\n",
            "/content/processed/6/011190.fea\n",
            "/content/processed/6/011060.fea\n",
            "/content/processed/6/049040.fea\n",
            "/content/processed/6/049000.fea\n",
            "/content/processed/6/018030.fea\n",
            "/content/processed/6/022140.fea\n",
            "/content/processed/6/034510.fea\n",
            "/content/processed/6/035470.fea\n",
            "/content/processed/6/070270.fea\n",
            "/content/processed/6/086050.fea\n",
            "/content/processed/6/075120.fea\n",
            "/content/processed/6/118240.fea\n",
            "/content/processed/6/086090.fea\n",
            "/content/processed/6/035010.fea\n",
            "/content/processed/6/051480.fea\n",
            "/content/processed/6/119320.fea\n",
            "/content/processed/6/126590.fea\n",
            "/content/processed/6/066090.fea\n",
            "/content/processed/6/035620.fea\n",
            "/content/processed/6/116770.fea\n",
            "/content/processed/6/032320.fea\n",
            "/content/processed/6/036100.fea\n",
            "/content/processed/6/034580.fea\n",
            "/content/processed/6/088730.fea\n",
            "/content/processed/6/035530.fea\n",
            "/content/processed/6/011100.fea\n",
            "/content/processed/6/011420.fea\n",
            "/content/processed/6/071280.fea\n",
            "/content/processed/6/129130.fea\n",
            "/content/processed/6/023010.fea\n",
            "/content/processed/6/011070.fea\n",
            "/content/processed/6/075510.fea\n",
            "/content/processed/6/077590.fea\n",
            "/content/processed/6/032990.fea\n",
            "/content/processed/6/116240.fea\n",
            "/content/processed/6/022080.fea\n",
            "/content/processed/6/074210.fea\n",
            "/content/processed/6/023090.fea\n",
            "/content/processed/6/049030.fea\n",
            "/content/processed/6/093050.fea\n",
            "/content/processed/6/022940.fea\n",
            "/content/processed/6/011040.fea\n",
            "/content/processed/6/049070.fea\n",
            "/content/processed/6/018070.fea\n",
            "/content/processed/6/119100.fea\n",
            "/content/processed/6/100220.fea\n",
            "/content/processed/6/099970.fea\n",
            "/content/processed/6/119030.fea\n",
            "/content/processed/6/102850.fea\n",
            "/content/processed/6/070480.fea\n",
            "/content/processed/6/030300.fea\n",
            "/content/processed/6/035120.fea\n",
            "/content/processed/6/093100.fea\n",
            "/content/processed/6/023100.fea\n",
            "/content/processed/6/017640.fea\n",
            "/content/processed/6/116720.fea\n",
            "/content/processed/6/066310.fea\n",
            "/content/processed/6/070540.fea\n",
            "/content/processed/6/116850.fea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnagsKyaudxp",
        "outputId": "d74ad4c0-903a-48c4-e16d-9a334b59ca3f"
      },
      "source": [
        "# Get test and train splits across \n",
        "\n",
        "train_df, val_df, test_df = get_dataset_splits(processed_df)\n",
        "model_input_dir = os.path.join(processed_dir, str(fips_state_code))\n",
        "create_folder(model_input_dir)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/processed/6' exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "93MX19S8275J",
        "outputId": "bed32606-5d06-4ac1-8acc-0772074c84d3"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>traffic_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-01 00:00:00</td>\n",
              "      <td>4868.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-01 01:00:00</td>\n",
              "      <td>3502.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-01 02:00:00</td>\n",
              "      <td>2526.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-01-01 03:00:00</td>\n",
              "      <td>1513.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-01-01 04:00:00</td>\n",
              "      <td>1363.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7267</th>\n",
              "      <td>2015-10-31 19:00:00</td>\n",
              "      <td>6790.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7268</th>\n",
              "      <td>2015-10-31 20:00:00</td>\n",
              "      <td>6558.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7269</th>\n",
              "      <td>2015-10-31 21:00:00</td>\n",
              "      <td>6660.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>2015-10-31 22:00:00</td>\n",
              "      <td>5771.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7271</th>\n",
              "      <td>2015-10-31 23:00:00</td>\n",
              "      <td>4181.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7272 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    date  traffic_volume\n",
              "0    2015-01-01 00:00:00          4868.0\n",
              "1    2015-01-01 01:00:00          3502.0\n",
              "2    2015-01-01 02:00:00          2526.0\n",
              "3    2015-01-01 03:00:00          1513.0\n",
              "4    2015-01-01 04:00:00          1363.0\n",
              "...                  ...             ...\n",
              "7267 2015-10-31 19:00:00          6790.0\n",
              "7268 2015-10-31 20:00:00          6558.0\n",
              "7269 2015-10-31 21:00:00          6660.0\n",
              "7270 2015-10-31 22:00:00          5771.0\n",
              "7271 2015-10-31 23:00:00          4181.0\n",
              "\n",
              "[7272 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "IPhOyBzj5FQn",
        "outputId": "0d84ddf3-95a7-4de5-ea30-8bb0cc53e630"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>traffic_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7272</th>\n",
              "      <td>2015-11-01 00:00:00</td>\n",
              "      <td>3022.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7273</th>\n",
              "      <td>2015-11-01 01:00:00</td>\n",
              "      <td>4519.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7274</th>\n",
              "      <td>2015-11-01 02:00:00</td>\n",
              "      <td>1300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7275</th>\n",
              "      <td>2015-11-01 03:00:00</td>\n",
              "      <td>1146.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7276</th>\n",
              "      <td>2015-11-01 04:00:00</td>\n",
              "      <td>1536.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>2015-12-31 19:00:00</td>\n",
              "      <td>8013.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8732</th>\n",
              "      <td>2015-12-31 20:00:00</td>\n",
              "      <td>6970.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8733</th>\n",
              "      <td>2015-12-31 21:00:00</td>\n",
              "      <td>6818.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8734</th>\n",
              "      <td>2015-12-31 22:00:00</td>\n",
              "      <td>5461.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8735</th>\n",
              "      <td>2015-12-31 23:00:00</td>\n",
              "      <td>3688.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1464 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    date  traffic_volume\n",
              "7272 2015-11-01 00:00:00          3022.0\n",
              "7273 2015-11-01 01:00:00          4519.0\n",
              "7274 2015-11-01 02:00:00          1300.0\n",
              "7275 2015-11-01 03:00:00          1146.0\n",
              "7276 2015-11-01 04:00:00          1536.0\n",
              "...                  ...             ...\n",
              "8731 2015-12-31 19:00:00          8013.0\n",
              "8732 2015-12-31 20:00:00          6970.0\n",
              "8733 2015-12-31 21:00:00          6818.0\n",
              "8734 2015-12-31 22:00:00          5461.0\n",
              "8735 2015-12-31 23:00:00          3688.0\n",
              "\n",
              "[1464 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y34J4X-My4RD",
        "outputId": "2ac6c7c8-4144-4d68-a4b1-209ba33c7854"
      },
      "source": [
        "import numpy as np\n",
        "from flaml import AutoML\n",
        "\n",
        "LOG_DIR = \"/content/logs\"\n",
        "create_folder(LOG_DIR)\n",
        "\n",
        "X_train = train_df[\"date\"].to_numpy()\n",
        "y_train = train_df[\"traffic_volume\"].to_numpy()\n",
        "automl = AutoML()\n",
        "\n",
        "automl.fit(X_train=X_train,\n",
        "           y_train=y_train,\n",
        "           metric= 'rmse',\n",
        "           period=24,  # time to forecast\n",
        "           task='forecast', \n",
        "           time_budget=60*5,  # time budget in seconds\n",
        "           log_file_name=f\"{LOG_DIR}/forecast-{fips_state_code}-{station_id}.log\",\n",
        "           estimator_list=[\"fbprophet\"]\n",
        "          )\n",
        "\n",
        "print(\"Predicting test_set\")\n",
        "y_pred = automl.predict(test_df[\"date\"].to_numpy())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 09-13 15:37:57] {1427} INFO - Evaluation method: cv\n",
            "INFO:flaml.automl:Evaluation method: cv\n",
            "[flaml.automl: 09-13 15:37:57] {1473} INFO - Minimizing error metric: rmse\n",
            "INFO:flaml.automl:Minimizing error metric: rmse\n",
            "[flaml.automl: 09-13 15:37:57] {1505} INFO - List of ML learners in AutoML Run: ['fbprophet']\n",
            "INFO:flaml.automl:List of ML learners in AutoML Run: ['fbprophet']\n",
            "[flaml.automl: 09-13 15:37:57] {1735} INFO - iteration 0, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 0, current learner fbprophet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/logs' exists.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:38:15] {1920} INFO -  at 18.9s,\tbest fbprophet's error=1410.6114,\tbest fbprophet's error=1410.6114\n",
            "INFO:flaml.automl: at 18.9s,\tbest fbprophet's error=1410.6114,\tbest fbprophet's error=1410.6114\n",
            "[flaml.automl: 09-13 15:38:15] {1735} INFO - iteration 1, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 1, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:38:34] {1920} INFO -  at 36.9s,\tbest fbprophet's error=1410.6114,\tbest fbprophet's error=1410.6114\n",
            "INFO:flaml.automl: at 36.9s,\tbest fbprophet's error=1410.6114,\tbest fbprophet's error=1410.6114\n",
            "[flaml.automl: 09-13 15:38:34] {1735} INFO - iteration 2, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 2, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:38:49] {1920} INFO -  at 52.2s,\tbest fbprophet's error=1410.6114,\tbest fbprophet's error=1410.6114\n",
            "INFO:flaml.automl: at 52.2s,\tbest fbprophet's error=1410.6114,\tbest fbprophet's error=1410.6114\n",
            "[flaml.automl: 09-13 15:38:49] {1735} INFO - iteration 3, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 3, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:39:07] {1920} INFO -  at 70.8s,\tbest fbprophet's error=1410.6114,\tbest fbprophet's error=1410.6114\n",
            "INFO:flaml.automl: at 70.8s,\tbest fbprophet's error=1410.6114,\tbest fbprophet's error=1410.6114\n",
            "[flaml.automl: 09-13 15:39:07] {1735} INFO - iteration 4, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 4, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:39:24] {1920} INFO -  at 87.6s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 87.6s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:39:24] {1735} INFO - iteration 5, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 5, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:39:41] {1920} INFO -  at 104.5s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 104.5s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:39:41] {1735} INFO - iteration 6, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 6, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:39:56] {1920} INFO -  at 119.7s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 119.7s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:39:56] {1735} INFO - iteration 7, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 7, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:40:16] {1920} INFO -  at 139.0s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 139.0s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:40:16] {1735} INFO - iteration 8, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 8, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:40:30] {1920} INFO -  at 153.5s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 153.5s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:40:30] {1735} INFO - iteration 9, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 9, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:40:49] {1920} INFO -  at 171.9s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 171.9s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:40:49] {1735} INFO - iteration 10, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 10, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:41:04] {1920} INFO -  at 187.9s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 187.9s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:41:04] {1735} INFO - iteration 11, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 11, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:41:19] {1920} INFO -  at 202.7s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 202.7s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:41:19] {1735} INFO - iteration 12, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 12, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:41:36] {1920} INFO -  at 219.5s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 219.5s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:41:36] {1735} INFO - iteration 13, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 13, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:41:52] {1920} INFO -  at 235.6s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 235.6s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:41:52] {1735} INFO - iteration 14, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 14, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:42:11] {1920} INFO -  at 254.6s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 254.6s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:42:11] {1735} INFO - iteration 15, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 15, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:42:28] {1920} INFO -  at 271.1s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 271.1s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:42:28] {1735} INFO - iteration 16, current learner fbprophet\n",
            "INFO:flaml.automl:iteration 16, current learner fbprophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:42:44] {1920} INFO -  at 287.5s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "INFO:flaml.automl: at 287.5s,\tbest fbprophet's error=1407.9515,\tbest fbprophet's error=1407.9515\n",
            "[flaml.automl: 09-13 15:42:44] {2021} INFO - selected model: <prophet.forecaster.Prophet object at 0x7f718437bfd0>\n",
            "INFO:flaml.automl:selected model: <prophet.forecaster.Prophet object at 0x7f718437bfd0>\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "[flaml.automl: 09-13 15:42:46] {2084} INFO - retrain fbprophet for 1.7s\n",
            "INFO:flaml.automl:retrain fbprophet for 1.7s\n",
            "[flaml.automl: 09-13 15:42:46] {2088} INFO - retrained model: <prophet.forecaster.Prophet object at 0x7f7184f0bf10>\n",
            "INFO:flaml.automl:retrained model: <prophet.forecaster.Prophet object at 0x7f7184f0bf10>\n",
            "[flaml.automl: 09-13 15:42:46] {1529} INFO - fit succeeded\n",
            "INFO:flaml.automl:fit succeeded\n",
            "[flaml.automl: 09-13 15:42:46] {1531} INFO - Time taken to find the best model: 87.61005783081055\n",
            "INFO:flaml.automl:Time taken to find the best model: 87.61005783081055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting test_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxuuy8Dm1U3Z"
      },
      "source": [
        "The following code blocks are commented out exploration done involving automl functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4yo0aS5ez8d"
      },
      "source": [
        "# input_window_size = 24*7\n",
        "# output_window_size = 24\n",
        "\n",
        "# X_train, y_train = get_sliding_windows(train_df[traffic_volume].to_numpy(),\n",
        "#                                        max_time, sub_window_size, stride_size)\n",
        "\n",
        "# # Initialize an AutoML instance\n",
        "# automl = AutoML()\n",
        "# # Specify automl goal and constraint\n",
        "# automl_settings = {\n",
        "#     \"time_budget\": 60*60,  # in seconds\n",
        "#     \"metric\": 'rmse',\n",
        "#     \"task\": 'regression',\n",
        "#     \"log_file_name\": f\"regression-automl-{fips_state_code}-{station_id}.log\",\n",
        "# }\n",
        "\n",
        "# # Train with labeled input data\n",
        "# automl.fit(X_train=X_train, y_train=y_train,\n",
        "#            **automl_settings)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6csHwWuouvT"
      },
      "source": [
        "# config = {\"n_estimators\": 46, \"num_leaves\": 6, \"min_child_samples\": 2, \n",
        "#           \"learning_rate\": 0.2149808616613788, \"log_max_bin\": 9, \n",
        "#           \"colsample_bytree\": 0.7151028186528372, \n",
        "#           \"reg_alpha\": 0.004577823970660193, \n",
        "#           \"reg_lambda\": 0.014498060191184265}, \n",
        "\n",
        "# model = XGBRegressor(**config)\n",
        "# model.fit(X_train, y_train)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azUyBOa4haw-"
      },
      "source": [
        "# from prophet import Prophet\n",
        "\n",
        "# m = Prophet(changepoint_prior_scale=0.010000000000000002,\n",
        "#             seasonality_prior_scale=1.0, \n",
        "#             holidays_prior_scale=1.0, \n",
        "#             seasonality_mode=\"multiplicative\"           \n",
        "#             )\n",
        "# timestamp_col = \"date\"\n",
        "# data_col = \"traffic_volume\"\n",
        "# p_df = train_df.rename(columns={timestamp_col : \"ds\",\n",
        "#                                data_col : \"y\"})\n",
        "# m.fit(p_df)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B4bgPrPor4P"
      },
      "source": [
        "# with open(f\"prohet-{fips_state_code}-{station_id}\", 'wb') as f:\n",
        "#     pickle.dump(m, f)\n",
        "\n",
        "# with open(f\"prohet-{fips_state_code}-{station_id}\", 'rb') as f:\n",
        "#     m = pickle.load(f)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t46XxCTwc_3"
      },
      "source": [
        "# p_test_df = test_df.rename(columns={timestamp_col : \"ds\"})\n",
        "# forecast = m.predict(p_test_df)\n",
        "# forecast"
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}